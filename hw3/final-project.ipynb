{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project for MP\n",
    "\n",
    "**(d)** (N points) Let's add some extra features. Use the features that you believe will help detecting code clone. (For example, the count of Java keywords: specifically, for a Java function, how many 'if', how many 'try'? ... and so on.) Please feel free to design your own features.\n",
    "\n",
    "Here are several steps you might want to take to add the new features (you are welcomed to use different approaches):\n",
    "* Write a function that when given a code snippet, returns the features.\n",
    "* Write a function to create a dataframe for the features you designed.\n",
    "* Write a function that uses ``ColumnTransformer`` to combine unigram and the designed features.\n",
    "* Re-train your logistic regression model over the combined features.\n",
    "\n",
    " What is the 10-fold cross validation accuracy? (Make sure to use the same folds as before, so the results are comparable!)\n",
    " \n",
    "**(e)** (N points) Finally, some analysis: essentially, we have trained two models: LR with unigrams and bigrams, and LR with unigrams and features you designed. This setting allows us to compare the power of the new features (bigrams/features you designed). Which one is the better feature for the code clone detection task? Explain why this may be true. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR with unigrams and bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "\n",
    "dataset = load_files(\"code-clone/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LogisticRegression(random_state=3, solver='liblinear')\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
    "X_train = vectorizer.fit_transform(dataset.data)\n",
    "y_train = dataset.target\n",
    "\n",
    "lr_cross_val_score = cross_val_score(lr_model, X_train, y_train, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Logistic Regression: 0.7565 (+/- 0.0663)\n"
     ]
    }
   ],
   "source": [
    "if lr_cross_val_score is not None:\n",
    "    print(\"Accuracy for Logistic Regression: %0.4f (+/- %0.4f)\" % (lr_cross_val_score.mean(), lr_cross_val_score.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR with extra features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using w2v embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_embeddings = load_files('code-clone-embeddings-left', encoding=\"utf-8\")\n",
    "right_embeddings = load_files('code-clone-embeddings-right', encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_cols(prefix):\n",
    "    return dict(zip(range(128), [f'{prefix}{i}' for i in range(128)]))\n",
    "\n",
    "index = dict(enumerate(dataset.filenames))\n",
    "\n",
    "les = pd.Series(left_embeddings.data, dtype='str', name='left')\n",
    "le = les.str.split(',', expand=True)\n",
    "le = le.rename(columns=rename_cols('l')).astype('float')\n",
    "\n",
    "res = pd.Series(right_embeddings.data, dtype='str', name='right')\n",
    "re = res.str.split(',', expand=True)\n",
    "re = re.rename(columns=rename_cols('r')).astype('float')\n",
    "\n",
    "body = pd.Series(dataset.data, name='body')\n",
    "\n",
    "df = pd.concat([body, le, re], axis=1).rename(index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   code-clone/neg/19035955-23162862.txt\n",
      "body  b'public static void main(String[] args) throw...\n",
      "l0                                            -0.051221\n",
      "l1                                            -0.122162\n",
      "l2                                             0.101226\n",
      "l3                                            -0.021237\n",
      "...                                                 ...\n",
      "r123                                          -0.049509\n",
      "r124                                          -0.022985\n",
      "r125                                           0.131543\n",
      "r126                                           0.082626\n",
      "r127                                           0.082103\n",
      "\n",
      "[257 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.head(1).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = ColumnTransformer([\n",
    "    (\"body\", CountVectorizer(), \"body\"),\n",
    "], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LogisticRegression(random_state=3, solver='liblinear')\n",
    "\n",
    "X_train = vectorizer.fit_transform(df)\n",
    "y_train = dataset.target\n",
    "\n",
    "lr_cross_val_score = cross_val_score(lr_model, X_train, y_train, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Logistic Regression: 0.7520 (+/- 0.0552)\n"
     ]
    }
   ],
   "source": [
    "if lr_cross_val_score is not None:\n",
    "    print(\"Accuracy for Logistic Regression: %0.4f (+/- %0.4f)\" % (lr_cross_val_score.mean(), lr_cross_val_score.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
