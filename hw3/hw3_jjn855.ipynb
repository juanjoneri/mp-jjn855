{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECE W382V MACHINE PROGRAMMING\n",
    "\n",
    "# Homework 3 - due Sunday August 13 2022 at 11:59pm\n",
    "\n",
    "For this homework you will hand in (upload) to canvas:\n",
    "- a notebook renamed ``hw3_YourEID.ipynb``\n",
    "\n",
    "__Before submitting__, please reset your kernel and rerun everything from the beginning (`Kernel` >> `Restart and Run All`) and ensure your code outputs the correct answer. **Do NOT change the default data directory we provided**\n",
    "\n",
    "A perfect solution for this homework is worth **100** points. Note that there are two extra open-ended problems 4(d) 4(e). For programming tasks, make sure that your code can run using Python 3.5+. If you cannot complete a problem, include as much pseudocode **(as Python comment)** as possible for partial credit. However, make sure it does not have any output errors.Â **If there are any output errors, half of the points for that problem will be automatically deducted.**\n",
    "\n",
    "Collaboration: you are free to discuss the homework assignments with other students.  However, all of the code you write must be your own!\n",
    "\n",
    "Review extension and academic dishonesty policy here: https://jjessyli.github.io/courses/lin373#extension-policy\n",
    "\n",
    "For typing up your answers to non-programming problems, information can be found about Markdown cells for Jupyter Notebooks here: https://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Working%20With%20Markdown%20Cells.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please list any collaborators here:\n",
    "- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-26b6884599ae6360",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Problem 1: Logistic Regression Parameters (25 points)\n",
    "\n",
    "* **(a)** (5 points) Binary Logistic Regression\n",
    "In logistic regression, we know that when there are two classes an example can belong to ($y\\in\\{0,1\\}$), for an example with M features,\n",
    "    $$\n",
    "    p(y=1|x_1, x_2, ..., x_M) = \\frac{1}{1+\\exp{ (-\\sum_{j=1}^M w_j x_j-b) }}\n",
    "    $$\n",
    "    $$\n",
    "    p(y=0|x_1, x_2, ..., x_M) = 1-p(y=1|x_1, x_2, ..., x_M)\n",
    "    $$\n",
    "\n",
    "Generally, how many parameters does logistic regression estimate? Base your answer on the equations above, and explain all variables in your answer. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "answer-1a",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    " Note: before submitting this file, make sure the anwser cell is a markdown cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Answer\n",
    "There are **$M + 1$ parameters** where M is the number of features. (we need to estimate all the weights $w_1$ to $w_M$ as well as the independent term $b$)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **(b)** (10 points) Explain log likelihood, gradient descent, and how they are involved in logistic regression. \n",
    "\n",
    "Given a dataset of $N$ examples, briefly describe how these parameters are estimated. You do not need to lay out specific mathematical derivations, rather, provide the name(s) of the process(es) and give a few sentences describing the process. You can assume that all these examples will be used for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "answer-1b",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "Note: before submitting this file, make sure the anwser cell is a markdown cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Answer\n",
    "\n",
    "The general way in which we train a machine learning model is by minimizing a cost function. In the case of gradient descent we use the \"log likelyhood\" cost function, which returns a value close to 0 when our parameters predicts a values that are close to the actual classes, and a very large value when they predict a values that is very far away from them:\n",
    "\n",
    "LL: $\\sum_{i=1}^N (y_i \\times log(p_i)) + ((1 - y_i) \\times log(1-p_i)$\n",
    "\n",
    "The log likelyhood function is convex, meaning that it has a single minimum (a set of parameters that achieve a lowest cost over the training set) that we can find using gradient descent. Gradient descent is a technique used to programatically find minimums in a function by taking small steps towards the direction of decreasing slope (derivative). The general algorithm is given by:\n",
    "\n",
    "$w_j' := w_j - \\alpha \\times \\frac{\\partial}{\\partial w_j} cost(W)$\n",
    "\n",
    "For the case of our log likelyhood cost function we get:\n",
    "\n",
    "$w_j' := w_j - \\alpha \\times \\sum_{i=1}^N (p_i - y_i) \\times x_{i_j}$\n",
    "\n",
    "In order to estimate or \"fit\" our parameters for this model, we would repeat this step several times, updating our parameters by a small ammount every time, until the cost converges somewehre close to its global minimum.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **(c)** (10 points) Logistic regression can be extended to classify $K$ classes instead of only 2. When $y$ can be one of K classes, the conditional probability of $y$ being of a particular class $k$ is:\n",
    " $$\n",
    " p(y=k|x_1,x_2,...,x_M) = \\frac{\\exp(\\sum_{j=1}^M w_{jk}x_j+b_k)}{\\sum_{k'=1}^K\\exp(\\sum_{j=1}^M w_{jk'}x_j+b_{k'})}\n",
    " $$\n",
    "How many parameters are we estimating in this case? Base your answer on the equations above, and explain all variables in your answer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "answer-1c",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "Note: before submitting this file, make sure the anwser cell is a markdown cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Answer\n",
    "\n",
    "There are **$(K * M) + K$ parameters** where K is the number of classes and M is the number of features.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5d47eb738169f49f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Problem 2: Regularization (25 points)\n",
    "\n",
    "Recall that with L2 regularization, we add a _regularization_ term to the log likelihood:\n",
    "$$\n",
    "    l({\\bf w}) = \\log \\prod_{i=1}^N{ p(y^{(i)}|{\\bf x^{(i)},w})}-\\lambda||{\\bf w}||_2^2\n",
    "$$\n",
    "\n",
    "* **(a)** (10 points) What is the goal of this regularization term? Describe how it works in one sentence. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "answer-2a",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "Note: before submitting this file, make sure the anwser cell is a markdown cell\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Answer\n",
    "\n",
    "Explain what is the regularization term in log likelyhood\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **(b)** (15 points) Your friend David uses cross validation to pick $\\lambda$ for his application of logistic regression as follows. First, he sets aside 20\\% of his data as a test set. Often the test set is predefined for you. Next, in order to determine which hyper-parameters to use for his final training, he runs cross validation on his training data. The results of these tuning expeiments are reported in column (a). Unsure which number to report, David also trains a model on the entire training data for each value of $\\lambda$ and computes test accuracy on his held out test data, as reported in column (b).\n",
    "He gets the following results:\n",
    "\n",
    "| $\\lambda$ | (a) Cross-validation accuracy | Test accuracy|\n",
    "|:---------:|:-------------------------:|:-------------:|\n",
    "|     0     |            0.71           |      0.65     |\n",
    "|     1     |            0.75           |      0.70     |\n",
    "|     10    |            0.80           |      0.63     |\n",
    "|    100    |            0.72           |      0.64     |\n",
    "\n",
    "* **(b-i)** What is the optimal $\\lambda$ in terms of test accuracy? Use the variable `optimal_test_accuracy`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-20d754030dda7fb6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "Note: before submitting this file, make sure the anwser cell is a markdown cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Answer\n",
    "\n",
    "Should we use the results of cross validation or from training on the entire train set and testing on test set?\n",
    "\n",
    "**From below it seems it should be from test set**\n",
    "\n",
    "`optimal_test_accuracy: 0.70` given by $\\lambda = 1$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **(b-ii)** Is this the same $\\lambda$ that would be chosen by cross validation? Use the variable `optimal_cross_validation`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-53232bb51fea7452",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "Note: before submitting this file, make sure the anwser cell is a markdown cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Answer\n",
    "\n",
    "No, it is not the same:\n",
    "\n",
    "`optimal_cross_validation: 0.80` given by $\\lambda = 10$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **(b-iii)** David wants to inform the public about his model and his results. What should he report as the test accuracy of his method (logistic regression with regularization parameter $\\lambda$) on this dataset? What lambda value does this correspond with? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f31fd5f701eca413",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "Note: before submitting this file, make sure the anwser cell is a markdown cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Answer\n",
    "\n",
    "He should report the optimal result obtained on the test set which is `0.70` given by $\\lambda = 1$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Multi-layer perceptron going linear (10 points)\n",
    "\n",
    "Show mathematically that a multi-layer perceptron using the _linear (identity) activation function_ $y=z$ is still a linear classifier. You can assume that (1) each example has two features $x_1$ and $x_2$; (2) there are two hidden layers; (3) each hidden layer has two nodes; (4) this is for a binary classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: before submitting this file, make sure the anwser cell is a markdown cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Answer\n",
    "\n",
    "Need to expand the computation of an input and show that the expression is linear\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4: Logistic Regression in sklearn (40 points)\n",
    "\n",
    "Logistic regression, it turns out, is a natural \"cousin\" to Naive Bayes; specifically it is the \"discriminative\" variant. First, let's review the modified code for the sklearn version of Naive Bayes (sentiment analysis notebook on Canvas Files/session_2/sentiment-analysis.ipynb). \n",
    "Instead of sentiment analysis, we apply models to do **Code Clone Detection**: given two Java functions as the input (two functions are concatenated by a special token `[CLS]`), the task is to do binary classification (0/1), where 1 stands for equivalence and 0 for others.\n",
    "Note that define a random state = 3, so that the answers will be consistent across everyone (it should be 0.66)! \n",
    "\n",
    "```\n",
    ">>> print(\"nb_model accuracy is : \", accuracy_score_nb)\n",
    "nb_model accuracy is :  0.66\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not change\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# load data using sklearn.datasets.load_files\n",
    "dataset = load_files(\"code-clone/\")\n",
    "\n",
    "# split the data into train and test\n",
    "docs_train, docs_test, y_train, y_test = train_test_split(dataset.data, dataset.target, test_size = 0.2, random_state = 3)\n",
    "\n",
    "# vectorize the training data\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(docs_train)\n",
    "\n",
    "# fit the model with the training data\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# vectorize the test data and predict \n",
    "X_test = vectorizer.transform(docs_test)\n",
    "y_hat_nb = nb_model.predict(X_test)\n",
    "\n",
    "# get accuracy score\n",
    "accuracy_score_nb = metrics.accuracy_score(y_test, y_hat_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_model accuracy is :  0.66\n",
      "classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.67      0.66       195\n",
      "           1       0.68      0.65      0.66       205\n",
      "\n",
      "    accuracy                           0.66       400\n",
      "   macro avg       0.66      0.66      0.66       400\n",
      "weighted avg       0.66      0.66      0.66       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Do not change\n",
    "print(\"nb_model accuracy is : \", accuracy_score_nb)\n",
    "print(\"classification report:\\n\", metrics.classification_report(y_test, y_hat_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a)** (15 points) Using the code for NaiveBayes, implement [logistic regression model provided by sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). How do the two models compare in terms of predictive performance? (Use random state 3 and 'liblinear' solver for LogisticRegression for this and all the following problems)\n",
    "\n",
    "```\n",
    ">>> print(\"lr_model accuracy is : \", metrics.accuracy_score(y_test, y_hat_lr))\n",
    "lr_model accuracy is :  0.7025\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6fdc13b1e29e1fad",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# use random_state = 3, solver='liblinear'\n",
    "y_hat_lr = None  # prediction of the logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not change\n",
    "if y_hat_lr is not None:\n",
    "    print(\"lr_model accuracy is : \", metrics.accuracy_score(y_test, y_hat_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1225245cd0051265",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Which model is better?\n",
    "# initialize (hardcode) the variable better_basic_model with either the string \"nb\" or \"lr\"\n",
    "Better_basic_model = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)** (15 points) Instead of performing just one train/test split, try performing cross validation using the sklearn function `cross_val_score`. [See here for documentation on doing this](https://scikit-learn.org/stable/modules/cross_validation.html). Using 10-fold cross-validation, retrain and run both NB and LR. For cross validation, because the evaluator will automatically section your data for you, make sure to:\n",
    "* define new NB/LR models\n",
    "* fit your (new) vectorizer on the entire dataset\n",
    "* use the entire dataset in the socring function `cross_val_score`\n",
    "\n",
    "```\n",
    ">>> print(\"Accuracy for Logistic Regression: %0.4f (+/- %0.4f)\" % (lr_xval_scores.mean(), lr_xval_scores.std() * 2))  \n",
    ">>> print(\"Accuracy for Naive Bayes: %0.4f (+/- %0.4f)\" % (nb_xval_scores.mean(), nb_xval_scores.std() * 2))  \n",
    "Accuracy for Logistic Regression: 0.7505 (+/- 0.0550)\n",
    "Accuracy for Naive Bayes: 0.7295 (+/- 0.0771)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b23dc25a2ffb21eb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "lr_xval_scores = None  # lr_xval_scores is returned by applying cross_val_score() to logistic regression model\n",
    "nb_xval_scores = None  # nb_xval_scores is returned by applying cross_val_score() to naive bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not change\n",
    "if lr_xval_scores is not None:\n",
    "    print(\"Accuracy for Logistic Regression: %0.4f (+/- %0.4f)\" % (lr_xval_scores.mean(), lr_xval_scores.std() * 2))\n",
    "if nb_xval_scores is not None:\n",
    "    print(\"Accuracy for Naive Bayes: %0.4f (+/- %0.4f)\" % (nb_xval_scores.mean(), nb_xval_scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-17788de9ee0fdc4d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Which model is better?\n",
    "# initialize (hardcode) the variable better_cv_model with either the string \"nb\" or \"lr\"\n",
    "better_cv_model = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c)** (10 points) Now, let's modify the featurres in our classifier! The first thing we're trying is to have our classifier not only include unigrams, but also bigrams. Modify your `CountVectorizer` to include bigrams and use logistic regression as your classifier. Did the results on 10-fold cross validation improve? (Make sure to use the same folds as before, so the results are comparable!)\n",
    "\n",
    "Hint: take a look at the CountVectorizer documentation -- you only need to change one parameter in this function to enable bigrams!\n",
    "\n",
    "\n",
    "```\n",
    ">>> print(\"Accuracy for Logistic Regression: %0.4f (+/- %0.4f)\" % (lr_bigram_scores.mean(), lr_bigram_scores.std() * 2))  \n",
    ">>> print(\"Accuracy for Naive Bayes: %0.4f (+/- %0.4f)\" % (nb_bigram_scores.mean(), nb_bigram_scores.std() * 2))  \n",
    "Accuracy for Logistic Regression: 0.7565 (+/- 0.0663)\n",
    "Accuracy for Naive Bayes: 0.7250 (+/- 0.0621)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-81286f74a36745a6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "lr_bigram_scores = None  # lr_bigram_scores is returned by applying cross_val_score() to logistic regression model\n",
    "nb_bigram_scores = None  # nb_bigram_scores is returned by applying cross_val_score() to navie bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not change\n",
    "\n",
    "if lr_bigram_scores is not None:\n",
    "    print(\"Accuracy for Logistic Regression: %0.4f (+/- %0.4f)\" % (lr_bigram_scores.mean(), lr_bigram_scores.std() * 2))\n",
    "if nb_bigram_scores is not None:\n",
    "    print(\"Accuracy for Naive Bayes: %0.4f (+/- %0.4f)\" % (nb_bigram_scores.mean(), nb_bigram_scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d)** (N points) Let's add some extra features. Use the features that you believe will help detecting code clone. (For example, the count of Java keywords: specifically, for a Java function, how many 'if', how many 'try'? ... and so on.) Please feel free to design your own features.\n",
    "\n",
    "Here are several steps you might want to take to add the new features (you are welcomed to use different approaches):\n",
    "* Write a function that when given a code snippet, returns the features.\n",
    "* Write a function to create a dataframe for the features you designed.\n",
    "* Write a function that uses ``ColumnTransformer`` to combine unigram and the designed features.\n",
    "* Re-train your logistic regression model over the combined features.\n",
    "\n",
    " What is the 10-fold cross validation accuracy? (Make sure to use the same folds as before, so the results are comparable!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(e)** (N points) Finally, some analysis: essentially, we have trained two models: LR with unigrams and bigrams, and LR with unigrams and features you designed. This setting allows us to compare the power of the new features (bigrams/features you designed). Which one is the better feature for the code clone detection task? Explain why this may be true. "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "64523368cfcc0679ac832abc9db724d4345cf20694ed59ab9f6cbea697d5fbf9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
