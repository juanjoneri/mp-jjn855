{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess code-clone dataset\n",
    "## Generates and loads w2v embeddings for each pair of functions in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment Constants\n",
    "\n",
    "## Download token_vecs.txt from https://s3.amazonaws.com/code2vec/model/token_vecs.tar.gz\n",
    "## Run `tar -xvzf token_vecs.tar.gz` to extract\n",
    "pretrained_w2v_model_path = 'data/word2vec-trained/tokens/token_vecs.txt'\n",
    "code_clone_dataset_path = 'code-clone'\n",
    "token_divider = '[cls]'\n",
    "\n",
    "## There should be a 'pos' and 'neg' subdirectory under each of these:\n",
    "left_embeddings_output_dir = 'code-clone-embeddings-left'\n",
    "right_embeddings_output_dir = 'code-clone-embeddings-right'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "from gensim.models import KeyedVectors as word2vec\n",
    "from gensim.test.utils import datapath\n",
    "from os import walk, path\n",
    "from sklearn.datasets import load_files\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('equalsignorecase', 0.5233527421951294),\n",
       " ('areequal', 0.47283560037612915),\n",
       " ('identityequals', 0.4442278742790222),\n",
       " ('indexrangekey', 0.4407910704612732),\n",
       " ('browserelements', 0.43472132086753845),\n",
       " ('streamq', 0.4342491328716278),\n",
       " ('equal', 0.43297117948532104),\n",
       " ('isequal', 0.4325423240661621),\n",
       " ('negativearrowvisible', 0.43036386370658875),\n",
       " ('pwdlen', 0.42697927355766296)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the pretrained Java w2v token embeddings\n",
    "\n",
    "tokens = word2vec.load_word2vec_format(pretrained_w2v_model_path, binary=False)\n",
    "tokens.most_similar(positive=['equals', 'tolower'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_document_embeddings(data):\n",
    "    \"\"\"Process one document: get the average of the token embeddings for the left and right functions.\"\"\"\n",
    "    left = []\n",
    "    right = []\n",
    "    current = left\n",
    "\n",
    "    for token in (t.lower() for t in ' '.join(data).split()):\n",
    "        if token == token_divider:\n",
    "            current = right\n",
    "        elif token in tokens:\n",
    "            current.append(tokens[token])\n",
    "\n",
    "    return np.mean(left, axis=0), np.mean(right, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_array_to_str(array):\n",
    "    \"\"\"custom str method for numpy array that joins the elements with `,`\"\"\"\n",
    "    return ','.join((str(x) for x in array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the code-clone dataset, generate the document embeddings and save them to the output directories\n",
    "\n",
    "for (dirpath, dirnames, filenames) in walk(code_clone_dataset_path):\n",
    "    for filename in filenames:\n",
    "        file = path.join(dirpath, filename)\n",
    "        pos = 'pos' if 'pos' in dirpath else 'neg'\n",
    "        output_l = path.join(left_embeddings_output_dir, pos, filename)\n",
    "        output_r = path.join(right_embeddings_output_dir, pos, filename)\n",
    "\n",
    "        with open(file, 'r') as f:\n",
    "            left, right = get_document_embeddings(f.readlines())\n",
    "            with open(output_l, \"w\") as out:\n",
    "                out.write(np_array_to_str(left))\n",
    "            with open(output_r, \"w\") as out:\n",
    "                out.write(np_array_to_str(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'-0.05122124,-0.12216224,0.101226486,-0.021237344,-0.042222623,0.05646271,0.044890355,0.121772684,-0.1112092,0.19515315,-0.031402837,0.07099562,0.0016093374,-0.0136487335,-0.10884587,-0.09148396,0.10080034,0.12520233,-0.03916842,0.055381935,0.08611373,-0.18527326,0.058904864,-0.02254408,0.16800413,0.072488315,0.09183001,0.027677659,0.0319309,0.16355889,-0.09993939,-0.06628542,-0.019778844,0.13314123,0.025044981,0.046441235,-0.22238311,-0.028121132,-0.0544777,-0.08333411,0.12823798,-0.03361119,0.023782631,-0.15554741,0.10700291,0.056919258,-0.06639689,-0.0538708,-0.12804495,0.08812185,-0.106228866,-0.14831069,0.17591883,0.05220724,0.032535713,-0.036819734,0.02613903,-0.15982021,0.04480314,-0.0609802,0.22196603,0.010189606,0.18794441,0.13692869,-0.00090712175,0.093317926,0.014242549,-0.023852697,-0.09821846,0.09576436,-0.034287006,-0.03790975,-0.0057899123,-0.06626237,0.05633267,-0.052551094,-0.10690658,-0.11371188,-0.017713418,0.096476145,0.017423538,0.13760008,-0.05342849,0.011066714,-0.00493763,0.08251008,-0.03861205,-0.026819587,-0.019720899,-0.012848404,0.009929351,0.09204518,-0.084339686,0.00788488,0.02793382,-0.091971934,-0.033164483,-0.023150504,-0.119268045,-0.08202492,-0.029129108,-0.01376756,0.005945891,-0.15058912,-0.20688882,-0.05368351,0.028776957,-0.106986694,-0.1846694,-0.06189811,-0.01868332,0.010481603,0.045447808,0.05419768,-0.10764699,0.0088846795,-0.117657885,-0.061946414,0.052142028,-0.07034004,0.00794203,-0.13668285,-0.12951636,0.022781625,-0.06917937,0.114890374,-0.012911535,0.054142755'\n"
     ]
    }
   ],
   "source": [
    "# Import the embeddings we just generated into memory\n",
    "\n",
    "left_embeddings = load_files(left_embeddings_output_dir)\n",
    "right_embeddings = load_files(right_embeddings_output_dir)\n",
    "\n",
    "print(left_embeddings.data[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
