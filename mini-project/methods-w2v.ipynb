{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and load w2v embeddings for method names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment Constants\n",
    "\n",
    "code_clone_dataset_path = 'code-clone'\n",
    "\n",
    "## There should be a 'pos' and 'neg' subdirectory under each of these:\n",
    "left_embeddings_output_dir = 'code-clone-method-embeddings-left'\n",
    "right_embeddings_output_dir = 'code-clone-method-embeddings-right'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "from re import finditer\n",
    "from os import walk, path\n",
    "from sklearn.datasets import load_files\n",
    "\n",
    "import re\n",
    "import os\n",
    "import gensim.downloader as api\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create needed directories\n",
    "for directory in [left_embeddings_output_dir, right_embeddings_output_dir]:\n",
    "    for subdir in ['pos', 'neg']:\n",
    "        final_dir = path.join(directory, subdir)\n",
    "        os.makedirs(final_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def camel_case_split(identifier):\n",
    "    \"\"\"Splits a method name by camel case doSomething -> [do, something].\"\"\"\n",
    "    # https://stackoverflow.com/a/29920015\n",
    "    matches = finditer('.+?(?:(?<=[a-z])(?=[A-Z])|(?<=[A-Z])(?=[A-Z][a-z])|$)', identifier)\n",
    "    return [m.group(0).lower() for m in matches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_method_names(document):\n",
    "    \"\"\"Extract the two method names from a code-clone document.\"\"\"\n",
    "    left, right = document.split('[CLS]')\n",
    "    pat = re.compile(r'(?:public|private|static|protected|abstract|native|synchronized)?\\s*\\w+\\s*(\\w+)\\s*\\(')\n",
    "    match_l = pat.search(left)\n",
    "    match_r = pat.search(right)    \n",
    "    return camel_case_split(match_l.group(1)), camel_case_split(match_r.group(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_document_embeddings(data):\n",
    "    \"\"\"Process one document: get the average of the token embeddings for the left and right function names.\"\"\"\n",
    "    left = []\n",
    "    right = []\n",
    "    \n",
    "    left_f, right_f = get_method_names(' '.join(data))\n",
    "\n",
    "    for token in left_f:\n",
    "        if token in model:\n",
    "            left.append(model[token])\n",
    "            \n",
    "    for token in right_f:\n",
    "        if token in model:\n",
    "            right.append(model[token])\n",
    "            \n",
    "    if len(left) == 0:\n",
    "        left.append(np.random.normal(0, 0.1, size=(300,)))\n",
    "    if len(right) == 0:\n",
    "        right.append(np.random.normal(0, 0.1, size=(300,)))\n",
    "\n",
    "    return np.mean(left, axis=0), np.mean(right, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_array_to_str(array):\n",
    "    \"\"\"custom str method for numpy array that joins the elements with `,`\"\"\"\n",
    "    return ','.join((str(x) for x in array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Load the w2v embeddings trained on google news 300 dataset\n",
    "\n",
    "model = api.load(\"word2vec-google-news-300\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the code-clone dataset, generate the document embeddings and save them to the output directories\n",
    "\n",
    "for (dirpath, dirnames, filenames) in walk(code_clone_dataset_path):\n",
    "    for filename in filenames:\n",
    "        file = path.join(dirpath, filename)\n",
    "        pos = 'pos' if 'pos' in dirpath else 'neg'\n",
    "        output_l = path.join(left_embeddings_output_dir, pos, filename)\n",
    "        output_r = path.join(right_embeddings_output_dir, pos, filename)\n",
    "\n",
    "        with open(file, 'r') as f:\n",
    "            left, right = get_document_embeddings(f.readlines())\n",
    "            with open(output_l, \"w\") as out:\n",
    "                out.write(np_array_to_str(left))\n",
    "            with open(output_r, \"w\") as out:\n",
    "                out.write(np_array_to_str(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the embeddings that we just generated\n",
    "\n",
    "left_embeddings = load_files(left_embeddings_output_dir, encoding=\"utf-8\")\n",
    "right_embeddings = load_files(right_embeddings_output_dir, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.1640625,-0.068359375,0.16796875,-0.045898438,-0.045654297,-0.087402344,0.018920898,0.032958984,-0.021728516,0.17578125,0.18164062,0.06689453,0.24023438,0.20117188,-0.14257812,-0.1953125,0.060546875,-0.20898438,0.036865234,-0.12402344,0.024291992,0.1015625,-0.18261719,0.36132812,-0.09765625,-0.13476562,-0.049316406,0.14648438,0.17480469,-0.09716797,-0.0546875,-0.18652344,0.23925781,-0.04638672,-0.041748047,-0.078125,-0.30273438,0.17675781,-0.033691406,-0.16796875,0.049804688,-0.07421875,0.17773438,0.0625,-0.020019531,0.07470703,-0.017089844,-0.033203125,-0.036865234,-0.028320312,0.028930664,0.1328125,-0.064453125,-0.08105469,-0.084472656,-0.0015106201,-0.20800781,-0.048583984,0.21875,0.07128906,-0.06689453,0.30664062,0.09033203,0.0119018555,0.17871094,-0.12890625,-0.078125,-0.016357422,-0.07128906,0.07324219,-0.064453125,0.16601562,0.40429688,0.026000977,-0.35546875,0.032226562,0.09082031,0.09375,-0.0703125,0.02355957,0.08496094,-0.09277344,0.099609375,0.095214844,-0.14160156,-0.096191406,-0.15332031,-0.041015625,-0.15039062,0.040039062,0.018432617,-0.22753906,-0.080078125,-0.12988281,-0.13671875,-0.1328125,0.050048828,-0.1015625,-0.30078125,0.24121094,-0.11328125,0.05078125,0.119628906,-0.16796875,-0.091796875,0.26953125,-0.006011963,-0.016479492,0.22070312,0.09472656,-0.104003906,-0.2578125,0.020019531,-0.039794922,0.10839844,0.010803223,0.029418945,-0.17089844,0.35351562,0.025756836,-0.15234375,0.025756836,-0.100097656,0.008850098,-0.09863281,-0.013366699,-0.115722656,-0.13964844,-0.07421875,0.115234375,-0.057128906,-0.17675781,0.09814453,-0.0859375,0.11230469,-0.28320312,0.084472656,-0.30273438,0.03540039,-0.044677734,0.115722656,-0.049072266,0.38085938,-0.07373047,0.043945312,-0.057128906,-0.08642578,0.036376953,-0.15820312,0.045166016,-0.25585938,0.064453125,0.091796875,0.1640625,-0.09033203,0.095703125,-0.03125,-0.18164062,-0.09423828,-0.11035156,-0.14550781,0.049560547,-0.053710938,-0.022216797,0.19921875,-0.005584717,0.28710938,0.012329102,0.016479492,0.087402344,-0.22265625,-0.095214844,0.24316406,0.039794922,-0.0017700195,0.0146484375,0.044921875,-0.19726562,-0.18652344,0.0115356445,-0.13085938,-0.2265625,-0.05493164,0.08251953,0.042236328,0.22363281,0.028564453,0.10107422,0.19238281,0.08300781,-0.11816406,0.0390625,-0.014953613,0.16210938,0.07519531,-0.07714844,-0.15625,0.017089844,-0.08544922,-0.115234375,0.31835938,0.16308594,-0.07519531,-0.17285156,0.15625,0.078125,0.110839844,0.15917969,0.21289062,0.025146484,-0.14453125,0.09375,0.079589844,0.15917969,0.046875,-0.087890625,0.06640625,-0.22363281,0.05126953,0.13964844,-0.05102539,-0.0703125,0.17578125,0.003112793,0.0007286072,-0.009643555,0.022583008,0.06640625,0.05102539,0.15625,-0.20996094,0.004211426,0.0107421875,0.30859375,-0.037353516,-0.10058594,0.1953125,-0.076660156,-0.17675781,-0.0071411133,-0.030151367,0.09082031,-0.1953125,-0.15234375,0.0019683838,-0.07519531,0.08886719,0.104003906,0.015625,0.02758789,-0.015380859,0.03515625,0.19335938,-0.1953125,0.15332031,-0.03881836,-0.045166016,0.14648438,-0.1953125,0.09472656,-0.007019043,-0.3125,-0.009338379,0.140625,0.0066833496,0.16015625,0.04321289,-0.10058594,0.051513672,0.21875,-0.12890625,-0.21777344,-0.115234375,-0.29882812,0.09716797,-0.012939453,-0.20410156,-0.34765625,-0.28515625,-0.025390625,-0.13574219,0.03100586,-0.091796875,0.019165039,-0.06982422,0.22363281,-0.29882812,0.13671875,-0.04248047,-0.06591797,-0.15917969,-0.013122559,0.07763672,-0.083984375,-0.06201172,-0.0005912781,-0.0017471313,-0.110839844,0.07470703,-0.04272461\n"
     ]
    }
   ],
   "source": [
    "print(left_embeddings.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
